import requests
from bs4 import BeautifulSoup
import json
import csv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from sentence_transformers import SentenceTransformer

# Function to scrape Brainlox courses
def scrape_brainlox_courses(url):
    response = requests.get(url)
    if response.status_code != 200:
        print("Failed to retrieve the webpage")
        return []
    
    soup = BeautifulSoup(response.text, 'html.parser')
    courses = []
    
    course_elements = soup.find_all('div', class_='single-courses-box')
    
    for course in course_elements:
        name_tag = course.find('h3')
        name = name_tag.text.strip() if name_tag else "No Title"
        
        description_tag = course.find('p')
        description = description_tag.text.strip() if description_tag else "No Description"
        
        price_tag = course.find('span', class_='price-per-session')
        price = price_tag.text.strip() if price_tag else "Price not available"
        
        courses.append({
            'name': name,
            'description': description,
            'price': price
        })
    
    return courses

# Function to store courses in FAISS for vector search
def store_in_faiss(courses):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    
    # Convert courses into text format
    texts = [f"{course['name']} - {course['description']} (Price: {course['price']})" for course in courses]
    chunks = text_splitter.split_text(" ".join(texts))

    # Use HuggingFaceEmbeddings wrapper for SentenceTransformer
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # Store embeddings in FAISS
    vector_store = FAISS.from_texts(chunks, embedding_model)
    vector_store.save_local("brainlox_courses_faiss")

    print("Stored in FAISS successfully!")

# Function to save courses as CSV
def save_to_csv(courses, filename="brainlox_courses.csv"):
    keys = ["name", "description", "price"]
    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=keys)
        writer.writeheader()
        writer.writerows(courses)
    print(f"Saved data to {filename}")

# Function to save courses as JSON
def save_to_json(courses, filename="brainlox_courses.json"):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(courses, f, indent=4)
    print(f"Saved data to {filename}")

# Main execution
if __name__ == "__main__":
    url = "https://brainlox.com/courses/category/technical"
    courses_data = scrape_brainlox_courses(url)
    
    if courses_data:
        store_in_faiss(courses_data)
        save_to_csv(courses_data)
        save_to_json(courses_data)
        print(f"Scraped {len(courses_data)} courses and saved data successfully!")
    else:
        print("No courses found.")
